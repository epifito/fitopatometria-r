{
  "hash": "f369da2a42fb879177f3db785481c3ba",
  "result": {
    "markdown": "# Métricas básicas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Setup\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyverse, rio)\n```\n:::\n\n\n## Tipos de variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtener todos el mismo set de numeros aleatorios \nset.seed(0)\nn=100\n```\n:::\n\n\nEmpecemos simulando datos de incidencia\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nivel de individuo \nbinomial1 <- rbinom(\n  n=n,      # number of observations: sample size \n  size=1,   # number of trials  \n  p=0.3     # probability of success\n)\nbinomial1\nhist(binomial1)\nabline(v=mean(binomial1), col=\"red\")\n```\n:::\n\n\nAhora con submuestreo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinomial2 <- rbinom(\n  n=n,      # number of observations: sample size \n  size=10,  # number of trials: sub-sample \n  p=0.3     # probability of success\n)\nbinomial2\nhist(binomial2)\nrug(binomial2)\n\nabline(v=mean(binomial2), col=\"red\")  \n\ninc <- binomial2/10\n\n# Media poblacional = np \n10*0.3\n\n# Varianza = np(1-p)\n10*0.3*0.7\nsqrt(10*0.3*0.7)\n```\n:::\n\n\nDisribución beta para proporciones, limitada entre 0 y 1:  \n\n- Incidencia (o prevalencia) de la enfermedad a nivel de muestra o población: proporción de individuos enfermos. \n- Severidad: expresada como proporción del área del órgano afectado. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta1.5 <- rbeta(n = n, shape1 = 1, shape2 = 8)\nbeta5.1 <- rbeta(n = n, shape1 = 5, shape2 = 1)\n\nhist(beta1.5)\nrug(beta1.5)\nabline(v=mean(beta1.5), col=\"red\")\nhist(beta5.1)\nrug(beta5.1)\nabline(v=mean(beta5.1), col=\"red\")\n```\n:::\n\n\nCompilamos en un data frame / tibble ... \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndis_data <- tibble(inc, sev_cond= beta1.5) %>% \n  rowid_to_column(\"sample_id\")\ndis_data\n\ndis_data %>% \n  mutate(\n    inc_percen = inc*100, \n    sev_percen = sev_cond*100, \n    sev_media = sev_percen*inc)\n```\n:::\n\n\n\nVariables continuas reales. Ej. Tamaño de lesión, longitud de raiz, etc.\n\nGeneralmente se describen mediante la distribución normal. Sin embargo, esta incluye valores negativos. En este caso podemos simular datos con la distribución gamma, que no puede tomar valores negativos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntam_les <- rgamma(n = n, \n                shape = 10, # valor medio \n                scale = 1)\n\nhist(tam_les)\nrug(tam_les)\nabline(v=mean(tam_les), col=\"red\")\n```\n:::\n\n\nEsclerotos de sclerotinia por capítulo de girasol o nemaotodes por g de raiz son ejemplos de variables de conteos (variables discretas positivas o enteros). Estos pueden ser representados por una distribución de Poisson. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconteos <- rpois(n = n,\n                 lambda = 20 # media\n                 )\nhist(conteos)\nrug(conteos)\nabline(v=mean(conteos), col=\"red\")\n```\n:::\n\n\n## Manipulacion \n\nAhora veamos una manipulacion multi-nivel de un muestreo multi-regional e inter-anual. \nPara eso carguemos el dataset Olivo/bacteriosis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load(\"data/data.RData\")\nolivo <- rio::import(\"https://raw.githubusercontent.com/epifito/fitopatometria-r/main/data/olivo.csv\")\nolivo %>% view() \n```\n:::\n\n\n> dataset formato \"wide\" (planilla de campo) con 30 columnas de sev por arbol individual [datos simulados]\n\n2) Re-estructuracion ---\n\nPasamos de formato wide a long para hacer operaciones por grupos. \nOjo: No siempre debe hacerse este paso aunque nos habilita a group_by()+ summarise()\n  # le pedimos que apile las columnas conteniendo a las plantas 1 a 30\n  # el nombre de las columnas las apile en una columna llamada \"tree\"\n  # la observaciones de severidad las apile en una columna llamada sev\n  # el producto de este re-arreglo se llamará \"oli_long\"\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nolivo %>%   \n  pivot_longer(cols = `1`:`30`, \n         names_to = \"tree\",\n         values_to = \"sev\") -> oli_long \n```\n:::\n\n\nChequeamos cuántos árboles fueron evaluados en cada año/región/lote:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_long\n```\n:::\n\n\nChequeamos cuantos arboles se evaluaron por campo\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_long %>%  \n  group_by(year, loc, farm) %>% \n  summarise(n= sum(!is.na(sev))) %>%  \n  pivot_wider(names_from=year, \n              values_from = n)\n```\n:::\n\n\nImprimimos los 30 árboles de un mismo lote \n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_long %>%  \n  arrange(loc, year) %>%  \n  print(n=30)\n```\n:::\n\n\n- Incidencia \n\n(nivel lote - evolución interanual)\n\nProbamos el artilugio matemático que nos permitirá calcular la proporción de árboles enfermos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmuestra1 <- c(0,1)\nmean(muestra1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmuestra2 <- c(0,0,0,0,1)\nmean(muestra2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmuestra3 <- c(1,1,1,1,1,1,1,1,0,0)\nmean(muestra3)\n```\n:::\n\n\nAhora si, aplicaremos el artilugio a nuestros datos. \n\nTip: pueden ir seleccionando por lineas para ir probando el codigo antes de ejecutarlo por completo (seleccionar hasta antes de cada pipe, sino quedará abierta la sentencia)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n oli_long %>% \n  mutate(diseased = sev>0) %>%  \n  group_by(year, loc, farm) %>% \n  summarise(inc = mean(diseased, na.rm=TRUE)*100) %>%  \n  ungroup %>%  \n  arrange(loc, year) -> oli_inc \n```\n:::\n\n\nDamos print a \"oli_inc\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_inc\n```\n:::\n\n\nGraficamos oli_inc (una de las posibilidades)\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_inc %>%  \n  ggplot()+\n  # aes(x=factor(year), y=inc) +\n  aes(x=factor(year), y=inc, color=factor(farm)) +\n  geom_point() +\n  # geom_line() +\n  geom_line(aes(group=farm)) +\n  facet_grid(. ~ loc)\n```\n:::\n\n\n- Prevalencia \n\nNivel región - evolución interanual\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_inc %>% \n  mutate(diseased_farm = inc>0) %>%  \n  group_by(year, loc) %>% \n  summarise(prev = mean(diseased_farm, na.rm=TRUE)*100) %>%  \n  ungroup %>%  \n  arrange(loc,year) -> oli_prev\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noli_prev\n```\n:::\n\n\nPlot de oli_prev\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_prev %>%  \n  ggplot()+\n  aes(x=factor(year), y=prev, color=factor(loc)) +\n  geom_point() +\n  geom_line(aes(group=loc))\n```\n:::\n\n\n- Severidad\n\nCalculamos ambas severidades vistas en la introducción teórica\n\nNOTA: en el teórico la sev_cond daba \"NaN\" en aquellos casos en que todos los arboles tenian sev=0, y en el filtrado `sev[which(sev > 0)]`\nel vector quedaba vacío. \n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_long %>%  \n  group_by(year, loc, farm) %>% \n  summarise(\n    sev_media = mean(sev, na.rm=TRUE), \n    sev_cond =mean(sev[which(sev > 0)])) %>%  \n  ungroup %>%  \n  mutate_all(~replace(., is.nan(.), 0)) %>%  \n  arrange(loc, year) -> oli_sev\noli_sev\n```\n:::\n\n\nPrint `oli_sev`\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_sev\n```\n:::\n\n\nPlot `oli_sev`\n\n* Aprovechamos a usar una función muy eficiente que puede resultar una gran aliada en nuestro trabajo cotidiano: `stat_summary()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\noli_sev %>%  \n  ggplot()+\n  aes(x=loc, y =sev_media)+\n  geom_point(alpha=.3)+\n  facet_wrap(\"year\")+ \n  stat_summary(fun = mean, geom = \"crossbar\", col=\"blue\")+\n  stat_summary(aes(label=..y.. %>%  round(1)), \n               fun=mean, \n               geom=\"text\", size=4, vjust = -0.5)  +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) \n```\n:::\n",
    "supporting": [
      "1-metricas_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}